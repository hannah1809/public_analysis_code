task,description
ArchiStandard,"The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains.
This task, described in [Pinel et al., 2007](https://doi.org/10.1186/1471-2202-8-91) probes basic functions, such as button presses with the left or right hand, viewing horizontal and vertical checkerboards, reading and listening to short sentences, and mental computations (subtractions).
Visual stimuli were displayed in four 250-ms epochs, separated by 100ms intervals (i.e., 1.3s in total). Auditory  stimuli were generated from a recorded male voice (i.e., a total of 1.6s for motor instructions, 1.2-1.7s for sentences, and 1.2-1.3s for subtraction). The auditory or visual stimuli were shown to the participants for passive viewing or button response in event related paradigms. Informal inquiries undertaken after the MRI session confirmed that the experimental tasks were understood and followed correctly."
ArchiSpatial,"The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains.
This task includes the performance of (1) ocular saccade, (2) grasping and (3) orientation judgments on objects (the two different tasks were actually made on the same visual stimuli in order to characterize grasping-specific activity), (4) judging whether a hand photograph was the left or right hand or (5) was displaying the front or back. The same input stimuli were presented twice in order to characterize specific reponse to hand side judgment."
ArchiSocial,"The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains.
This task relies on (1) the interpretation of short stories involving false beliefs or not, (2) observation of moving objects with or without a putative intention, and (3) listening to speech and non-speech sounds."
ArchiEmotional,"The ARCHI tasks are a battery of localizers comprising a wide range of psychological domains.
This task includes (1) facial judgments of gender, and (2) trustworthiness plus expression based on complete portraits or photos of eyes’ expressions."
HcpEmotion,"The main purpose of HCP Emotion task was to capture neural activity arising from fear- or angry-response processes. To elicit stronger effects, affective facial expressions were used as visual stimuli due to their importance in adaptive social behavior [Hariri et al., 2002](https://doi.org/10.1006/nimg.2002.1179).
The paradigm was thus composed by two categories of blocks: (1) the face block, and (2) the shape block. All blocks consisted of a series of events, in which images with faces or shapes were displayed, respectively. There were always three faces/shapes per image; one face/shape was shown at the top and two faces/shapes were shown at the bottom. The participants were then asked to decide which face/shape at the bottom, i.e. left or right face/shape, matched the one displayed at the top, by pressing respectively the index or middle finger’s button of the response box.
The task was formed by twelve blocks per run, i.e. six face blocks and six shape blocks. The two block categories were alternately presented for each run. All blocks contained six trials and they were always initiated by a cue of three seconds. In turn, the trials included a visual-stimulus period of two seconds and a fixation-cross period of one second; the total duration of the trial was thus three seconds."
HcpGambling,"This task was adapted from the Incentive processing task-fMRI paradigm of the HCP and its aim was to localize brain structures that take part to the reward system, namely the basal ganglia complex.
The paradigm included eight blocks and each block was composed by eight events. For every event, the participants were asked to play a game. The goal was to guess whether the next number to be displayed, which ranged from one to nine, would be more or less than five while a question mark was shown on the screen. The answer was given by pressing the index or middle finger’s button of the response box, respectively. Feedback on the correct number was provided afterwards. There was an equal amount of blocks in which the participants experienced either reward or loss, for most of the events. Concretely, six out of the eight events within a block pertained to one of these two outcomes; the remaining events corresponded to the antagonist or a neutral outcome, i.e. when the correct number was five.
The task was constituted by eight blocks per run, in which each half related to reward and loss experience, respectively. The order of the two block categories were pseudorandomized during a single run, but fixed for all participants. A fixation-cross period of fifteen seconds was displayed between blocks. All blocks contained eight trials. The trials included a question-mark visual stimulus lasting up to 1.5 seconds, a feedback period of one second and a fixation-cross period of one second, as well; the total duration of the trial was then 3.5 seconds, approximately."
HcpMotor,"HCP Motor task was designed with the intent of extracting maps on gross motor topography, in particular motor skills associated with movements of the foot, hand and tongue.
There were thus five categories of blocks with respect to motor tasks involving (1) the left foot, (2) the right foot, (3) the left hand, (4) the right hand, and (5) the tongue, respectively. The blocks always started with visual cues referring to which part of the body should be moved. The cues were then followed by a set of events, which were in turn indicated by flashing arrows on the screen. The events pertained to the corresponding movements performed by the participants.
The task was formed by five blocks per category, with a total of twenty blocks per run. The order of the block categories were pseudo-randomized during each run, but fixed for all participants. A fixation-dot period of fifteen seconds was inserted between some blocks. All blocks contained ten trials. Every trial included a cue of one second and a period of performance of twelve seconds4; the total duration of the trial was then thirteen seconds."
HcpLanguage,"HCP Language task was used as a localizer of brain regions involved in semantic processing, with special focus on the anterior temporal lobe (ATL) [Binder et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.048).
The paradigm comprised two categories of blocks: (1) story blocks, and (2) math blocks. The math block served as a control task in this context, since it was likely to adress other brain regions during the attentional demands. Both type of blocks exhibited auditory stimuli in short epochs, which in turn finished with a final question followed by two possible answers. During story blocks, participants were presented with stories, whose question targeted their respective topics. Conversely, math blocks showed arithmetic problems for which the correct solution must be selected. The answer was provided after the two possible options were displayed, through pressing the corresponding button of the response box, i.e. the button for the index or middle finger of the response box for the first or second option, respectively. The difficulty levels of the problems, presented for both categories, were adjusted throughout the experiment, in order to keep the participants engaged in the task and, thus, assure accurate performances [Binder et al., 2011](https://doi.org/10.1016/j.neuroimage.2010.09.048).
The task was composed by eleven blocks per run. For the first run, six story blocks and five math blocks were interleaved, respectively. The reverse amount and order of blocks were used during the second run. The number of trials per block varied between one and four. Nevertheless, it was assured that both block categories matched their length of presentation at every run. There was a cue of two seconds in the beginning of each block, indicating its category. The duration of the trials within a block varied between ten and thirty seconds. Finally, the presentation of the auditory stimuli was always accompanied by the display of a fixation cross on the screen throughout the entire run."
HcpRelational,"HCP Relational task employed a relational matching-to-sample paradigm, featuring a second-order comparison of relations between two pairs of objects. It served primarily as a localizer of the rostrolateral prefrontal cortex, since relational matching mechanisms were shown to elicit activation on this region [Smith et al., 2007](https://doi.org/10.1016/j.neuroimage.2007.04.032).
Similarly to some previous tasks, two categories of blocks described the paradigm: (1) the relational-processing block, and (2) the control-matching block. All blocks were constituted by a set of events. In the relational-processing block, visual stimuli consisted of images representing two pairs of objects, in which one pair was placed at the top and the other one at the bottom of the image, respectively. Objects within a pair may differ in two dimensions: shape and texture. The participants had to identify whether the pair of objects from the top differed in a specific dimension and, subsequently, they were asked to determine whether the pair from the bottom changed along the same dimension. For the control block, one pair of objects was displayed at the top of the image and a single object at the bottom of the same image. In addition, a cue was shown in the middle of that image referring to one of the two possible dimensions. The participants had thus to indicate whether the object from the bottom was matching either of the two objects from the top, according to the dimension specified as a cue. If there was a match they had to press with the index finger on the corresponding button of the button box; otherwise, they had to press with the middle finger on the corresponding one.
This task was formed by twelve blocks per run. Two groups of six blocks referred to the two block categories, respectively. Block categories were, in turn, interleaved for display within a run. A fixation-cross period of sixteen seconds was inserted between some blocks. All blocks contained six trials and they were always initiated by a cue of two seconds. The trials were described by a visual-stimulus plus response period followed by a fixation-cross period, lasting up to ten seconds. The duration of the former differed in agreement with the type of block, i.e. it lasted nine seconds and 7.6 seconds during the relational-processing block and control-matching block, respectively."
HcpSocial,"HCP Social task intended to provide evidence for task-specific activation in brain structures presumably implicated in social cognition.
The paradigm included two categories of blocks, in which movies were presented during short epochs. The movies consisted in triangle-shape clip art, moving in a predetermined fashion. Putative social interactions could be drawn from movements referring to the block category on the effect-of-interest. In contrast, objects appeared to be randomly moving the other category, i.e. the control-effect block. Participants were to decide whether the movements of the objects appeared to represent a social interaction (by pressing with the index finger in the corresponding button of the response box) or not (by pressing with the ring finger in the corresponding button of the response box; in case of uncertainty, they had to press with the middle finger.
The task was constituted by ten blocks per run. Each half of the blocks corresponded to one of the aforementioned block categories, whose order was pseudo-randomized for every run, but fixed for all participants. There was only one trial present per block. It consisted of a twenty-second period of video-clip presentation plus three seconds maximum of a response period, indicated by a momentary instruction on the screen. Thus, the total duration of a block was approximately twenty three seconds. A fixation-cross period of fifteen seconds was always displayed between blocks. "
HcpWm,"HCP Working Memory task was adapted from the classical n-back task to serve as functional localizer for evaluation of working-memory (WM) capacity and related processes.
The paradigm integrated two categories of blocks: (1) the “0-back” WM-task block, and (2) the “2-back” WM-task block. They were both equally presented within a run. A cue was always displayed at the beginning of each block, indicating its task-related type. Blocks were formed by set of events, during which pictures of faces, places, tools or body parts were shown on the screen. One block was always dedicated to one specific category of pictures and the four categories were always presented at every run. At each event, the participant were to decide whether the image matched with the reference or not, by pressing respectively on the index or middle finger’s button of the response box.
The task was constituted by sixteen blocks per run, splitted into two block categories. Besides, there were four pairs of blocks per category, referring respectively to the four classes of pictures mentioned above. The order of the blocks, regardless their category and corresponding class of pictures, was pseudo-randomized for every run, but fixed for all participants. A fixation-cross period of fifteen seconds was introduced between some blocks. All blocks contained ten trials and they were always initiated by a cue of 2.5 seconds. Trials included in turn the presentation of a picture for two seconds and a very short fixation-cross period for half of a second; the total duration of one trial was thus 2.5 seconds."
RSVPLanguage,"The Rapid-Serial-Visual-Presentation (RSVP) Language task was adapted from the study undertaken by [Humphries et al., 2006](10.1162/jocn.2006.18.4.665) on syntactic and semantic processing during auditory sentence comprehension. Specifically, the task herein described targeted the same syntactic and semantic modules, but in the context of reading. It thus allowed for capturing further associations with regard to e.g. visual (pseudo) word recognition and sublexical route, among other aspects related to active reading.
The paradigm consisted in a block-design presentation strategy of the stimuli. One block was defined as an epoch within a trial and epochs corresponded in turn to experimental conditions. Such conditions stood for the consecutive visual presentation of ten constituents composed by letters.
All linguistic content elicited from the conditions except “consonant strings”, such as grammar rules, lexicon and phonemes, were part of the french language. In order to ensure continuous engagement during task performance, participants were asked, straight afterwards the visualization of every sentence, to ascertain whether the current constituent displayed on the screen, aka “the probe”, was part of the previous sentence or not. The corresponding answer was provided immediately after the probe, by pressing the button in the left hand if “yes” or the one in the right hand if “no”.
Data were collected in six runs during one single session. Every run was composed by sixty trials, in which subsets of ten trials were dedicated to each condition, respectively. The order of the trials was pseudo-randomized within and between runs, such that there were no repeated trials during a full session. Moreover, a different pseudo-randomized order for the presentation of the trials was always employed across participants. One trial comprised several experimental manipulations, other than a block integrating one specific condition. It was sequentially formed by a period of fixation-cross display (two seconds), another short period of a blank screen (0.5 seconds), a block containing the linguistic stimuli (0.4 seconds × 10 = 4 seconds), a jittered blank screen (varying from one to 1.5 seconds), a period of a second fixation-cross display (0.5 seconds), a period for the probe display (0.5 seconds), and, finally, a response period (varying up to two seconds). The total duration of one single trial was thus ten seconds. Three extra seconds of blank screen were added at the beginning of every run, i.e. before the presentation of the first trial.
Two opposite phase-encoding directions were respectively applied during acquisition of each half of the total amount of runs."
MTTWE,
MTTNS,
PreferenceFood,
PreferencePaintings,
PreferenceFaces,
PreferenceHouses,
TheoryOfMind,
EmotionalPain,
PainMovie,
VSTM,
Enumeration,
Self,
Bang,
Wedge,
Ring,
Lec2,
Audi,
Visu,
Lec1,
MVEB,
MVIS,
Moto,
MCSE,
Audio,
Attention,
StopSignal,
TwoByTwo,
Discount,
SelectiveStopSignal,
Stroop,
ColumbiaCards,
DotPatterns,
WardAndAllport,
BiologicalMotion1,
BiologicalMotion2,
MathLanguage,
SpatialNavigation,
EmoMem,
EmoReco,
StopNogo,
Catell,
FingerTapping,
VSTMC,
